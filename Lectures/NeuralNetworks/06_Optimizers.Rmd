---
jupyter:
  jupytext:
    cell_metadata_json: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python slideshow={'slide_type': 'skip'}}
# %load_ext autoreload
# %autoreload 2
```

```{python slideshow={'slide_type': 'skip'}}
from IPython.core.display import Image
```

```{python slideshow={'slide_type': 'slide'}}
Image(filename='../img//boromir.png')
```

<!-- #region {"slideshow": {"slide_type": "skip"}} -->
<!-- <img src='../img//boromir.png'/> 
<!-- #endregion -->

```{python slideshow={'slide_type': 'skip'}}
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import torch, torchvision
```

```{python slideshow={'slide_type': 'skip'}}
import sys
sys.path.append('../../mchlearn/')
import utils
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
# Optimizers
<!-- #endregion -->

[An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/)

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## Gradient Descent
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\begin{align}
\theta_{t+1}& = \theta^{t}-\eta\nabla_\theta L(\theta_t)
\end{align}
$$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
data = np.load("../data/sgd_data.npy").astype('float32')
```

```{python}
sin_example = utils.SinFitExample(data)
```

```{python}
sin_example.display_data();
```

```{python slideshow={'slide_type': 'skip'}}
def fitf(x,o,t):
    return np.sin(x*o+t)

def fitf_tensor(x,o,t):
    return np.moveaxis(np.sin(np.tensordot(np.atleast_1d(x),o,0)+t),0,-1)

def mse(f, x, y, o, t):
        err = f(x,o,t)-y
        return 0.5*np.sum(err*err, axis=-1)/len(x)
```

```{python slideshow={'slide_type': 'skip'}}
t_rxs = torch.from_numpy(data[:400,0])
t_rys = torch.from_numpy(data[:400,1])
```

```{python slideshow={'slide_type': 'skip'}}
loss_f = torch.nn.MSELoss()
```

```{python slideshow={'slide_type': 'slide'}}
rdataset = torch.utils.data.TensorDataset(t_rxs, t_rys)
```

```{python slideshow={'slide_type': 'slide'}}
onebatchloader = torch.utils.data.DataLoader(rdataset, batch_size=len(rdataset), shuffle=False);
```

```{python slideshow={'slide_type': '-'}}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.SGD([p], lr=0.2)
sin_example.run_example(p, gd, onebatchloader);
```

```{python slideshow={'slide_type': 'slide'}}
batch_data_loader = torch.utils.data.DataLoader(rdataset, batch_size=50, shuffle=True)
```

```{python}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.SGD([p], lr=0.2)
sin_example.run_example(p, gd, batch_data_loader);
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## "Ravine"
<!-- #endregion -->

```{python slideshow={'slide_type': 'skip'}}
rav_par = np.asarray([1.0,10.0]).astype('float32')
```

```{python slideshow={'slide_type': 'skip'}}
ravine_example = utils.RavineExample(rav_par)
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 3])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.02)
ravine_example.run_example(p, gd,100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 0])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.02)
ravine_example.run_example(p, gd,100,1.0 );
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## Gradient Descent with Momentum
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\begin{align}
v_{t+1}& = \mu v_{t} + (1-\beta)\nabla_\theta L(\theta_t)\\
\theta_{t+1}& = \theta_{t}-\eta v_{t+1}
\end{align}
$$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 3])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.021, momentum=0.1)
ravine_example.run_example(p, gd,100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 0])
p.requires_grad_(True);
gd = torch.optim.SGD([p], lr=0.021, momentum=0.99)
ravine_example.run_example(p, gd,100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.SGD([p], lr=0.01, momentum=0.8)
sin_example.run_example(p, gd, batch_data_loader);
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
$$\begin{align}
v_{t+1}& = \mu v_{t} + (1-\beta)\nabla_\theta L(\theta_t)\\
\theta_{t+1}& = \theta_{t}-\eta v_{t+1}
\end{align}
$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_{t+1} = \mu v_{t} + (1-\beta)g_t$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_1 = (1-\beta)g_0$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_2 = \mu (1-\beta)g_0+(1-\beta) g_1$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_3 = \mu\left(\mu (1-\beta)g_0+(1-\beta) g_1\right)+(1-\beta)g_2$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
$$v_3 = \mu^2 (1-\beta)g_0+\mu (1-\beta) g_1
+(1-\beta)g_2$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$v_t = (1-\beta)\sum_{i=1}^t \mu^{i-1}g_{t-i}$$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
ns = np.arange(0,100)
for mu in [0.9, 0.7,0.5, 0.25]:
    plt.plot(ns,mu**ns,'.', label="%4.2f" % (mu,))
plt.legend();
```

<!-- #region {"slideshow": {"slide_type": "slide"}} -->
## Adam: Adaptive Momentum Estimation 
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\begin{split}
g_t &= \nabla_\theta L(\theta_t)\\
m_t &= \beta_1 m_{t-1} + (1-\beta_1) g_t \\
v_t &= \beta_2 v_{t-1} + (1-\beta_2) g^2_t \\
\end{split}
$$
<!-- #endregion -->

<!-- #region {"slideshow": {"slide_type": "fragment"}} -->
$$\theta_{t+1} = \theta_t -\frac{\eta}{\sqrt{v}+\epsilon}m_t $$
<!-- #endregion -->

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 3])
p.requires_grad_(True);
gd = torch.optim.Adam([p], lr=0.2, betas=(0.2, 0.1))
ravine_example.run_example(p, gd,2100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([-8, 0])
p.requires_grad_(True);
gd = torch.optim.Adam([p], lr=0.1, betas=(0.1, 0.2))
ravine_example.run_example(p, gd,2100,1.0 );
```

```{python slideshow={'slide_type': 'slide'}}
p = torch.FloatTensor([3.2,-0.4])
p.requires_grad_(True)
gd = torch.optim.Adam([p], lr=0.1, betas = (.1,.2 ))
sin_example.run_example(p, gd, batch_data_loader);
```
